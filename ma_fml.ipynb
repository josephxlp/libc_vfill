{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import numpy as np\n",
    "import rasterio\n",
    "import torch\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from catboost import CatBoostRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "def get_best_gpu():\n",
    "    \"\"\"Selects the best available GPU based on memory size.\"\"\"\n",
    "    if not torch.cuda.is_available():\n",
    "        return 'CPU'\n",
    "    \n",
    "    num_gpus = torch.cuda.device_count()\n",
    "    if num_gpus == 1:\n",
    "        return 'cuda:0'\n",
    "    \n",
    "    best_gpu = max(range(num_gpus), key=lambda i: torch.cuda.get_device_properties(i).total_memory)\n",
    "    return f'cuda:{best_gpu}'\n",
    "\n",
    "def read_dem(dem_path):\n",
    "    \"\"\"Reads a DEM file and returns the data as a NumPy array along with its metadata.\"\"\"\n",
    "    with rasterio.open(dem_path) as src:\n",
    "        data = src.read(1).astype(np.float32)  # Read first band\n",
    "        meta = src.meta\n",
    "    return data, meta\n",
    "\n",
    "def mask_invalid_values(data, nodata_value=-9999, min_valid=-999, max_valid=10000):\n",
    "    \"\"\"Masks out invalid values by setting them to NaN.\"\"\"\n",
    "    data = np.where((data <= min_valid) | (data >= max_valid) | (data == nodata_value), np.nan, data)\n",
    "    return data\n",
    "\n",
    "def interpolate_missing_values(data, model_type='catboost'):\n",
    "    \"\"\"Performs interpolation on missing values in a DEM using the specified model.\"\"\"\n",
    "    mask = np.isfinite(data)\n",
    "    coords = np.array(np.nonzero(mask)).T\n",
    "    values = data[mask]\n",
    "    missing_coords = np.array(np.nonzero(~mask)).T\n",
    "    \n",
    "    if len(values) == 0 or len(missing_coords) == 0:\n",
    "        print(\"No valid data to train the model or no missing values to interpolate.\")\n",
    "        return data\n",
    "    \n",
    "    model = None\n",
    "    device = get_best_gpu()\n",
    "    \n",
    "    if model_type == 'rf':\n",
    "        model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "    elif model_type == 'catboost':\n",
    "        model = CatBoostRegressor(iterations=1000, verbose=100, task_type='GPU' if 'cuda' in device else 'CPU', devices=[int(device.split(':')[-1])] if 'cuda' in device else None)\n",
    "    elif model_type == 'lightgbm':\n",
    "        model = LGBMRegressor(n_estimators=100, learning_rate=0.1)\n",
    "    elif model_type == 'xgboost':\n",
    "        model = XGBRegressor(n_estimators=100, learning_rate=0.1, objective='reg:squarederror')\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported model type. Choose from 'rf', 'catboost', 'lightgbm', or 'xgboost'.\")\n",
    "    \n",
    "    model.fit(coords, values)\n",
    "    data[~mask] = model.predict(missing_coords)\n",
    "    return data\n",
    "\n",
    "def save_dem(dem_path, data, meta):\n",
    "    \"\"\"Saves the processed DEM back to a file.\"\"\"\n",
    "    meta.update(dtype=rasterio.float32, nodata=np.nan)\n",
    "    with rasterio.open(dem_path, 'w', **meta) as dst:\n",
    "        dst.write(data, 1)\n",
    "\n",
    "def demvfill_byML(dem_ipath, dem_opath, model_type='catboost'):\n",
    "    \"\"\"Full pipeline: Read, mask, interpolate, and save the DEM.\"\"\"\n",
    "    print('read_dem')\n",
    "    data, meta = read_dem(dem_ipath)\n",
    "    print('mask_invalid_values')\n",
    "    data = mask_invalid_values(data)\n",
    "    print('interpolate_missing_values')\n",
    "    data = interpolate_missing_values(data, model_type)\n",
    "    print('save_dem')\n",
    "    save_dem(dem_opath, data, meta)\n",
    "    print('demvfill_byML')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda:1'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_best_gpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from upaths import OUT_TILES_DPATH\n",
    "import os\n",
    "\n",
    "X = 30\n",
    "outdir = f\"{OUT_TILES_DPATH}/DEMVFILL/TILES{X}\"\n",
    "tiles_xdpath = f\"{OUT_TILES_DPATH}/TILES{X}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- do hpo ? you mean ensemble here , and check other places as well \n",
    "- if this works, rolfs criteria: only radar data, and no extra data to merge, purly unsupervised ::: write a whole paper here \n",
    "- add features like dem derivatives to help the model make train and make prediction\n",
    "- check if the file exisit before loading data to run this, save the model in models directoy and load if existing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "tilenames = os.listdir(tiles_xdpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "read_dem\n",
      "mask_invalid_values\n",
      "interpolate_missing_values\n",
      "Learning rate set to 0.132733\n",
      "0:\tlearn: 1.8310222\ttotal: 25.1ms\tremaining: 25.1s\n",
      "100:\tlearn: 1.2310032\ttotal: 2.31s\tremaining: 20.5s\n",
      "200:\tlearn: 1.2066771\ttotal: 4.59s\tremaining: 18.3s\n",
      "300:\tlearn: 1.1944815\ttotal: 6.87s\tremaining: 16s\n",
      "400:\tlearn: 1.1866061\ttotal: 9.15s\tremaining: 13.7s\n",
      "500:\tlearn: 1.1798905\ttotal: 11.4s\tremaining: 11.4s\n",
      "600:\tlearn: 1.1744044\ttotal: 13.7s\tremaining: 9.12s\n",
      "700:\tlearn: 1.1691966\ttotal: 16s\tremaining: 6.82s\n",
      "800:\tlearn: 1.1653670\ttotal: 18.3s\tremaining: 4.54s\n",
      "900:\tlearn: 1.1620099\ttotal: 20.6s\tremaining: 2.26s\n",
      "999:\tlearn: 1.1589038\ttotal: 22.8s\tremaining: 0us\n",
      "save_dem\n",
      "demvfill_byML\n",
      "True\n",
      "read_dem\n",
      "mask_invalid_values\n",
      "interpolate_missing_values\n",
      "Learning rate set to 0.116232\n",
      "0:\tlearn: 2.1691458\ttotal: 11.4ms\tremaining: 11.4s\n",
      "100:\tlearn: 1.9065536\ttotal: 974ms\tremaining: 8.67s\n",
      "200:\tlearn: 1.8634730\ttotal: 1.92s\tremaining: 7.62s\n",
      "300:\tlearn: 1.8326660\ttotal: 2.88s\tremaining: 6.69s\n",
      "400:\tlearn: 1.8109035\ttotal: 3.84s\tremaining: 5.74s\n",
      "500:\tlearn: 1.7935410\ttotal: 4.79s\tremaining: 4.78s\n",
      "600:\tlearn: 1.7776664\ttotal: 5.74s\tremaining: 3.81s\n",
      "700:\tlearn: 1.7644959\ttotal: 6.7s\tremaining: 2.86s\n",
      "800:\tlearn: 1.7522820\ttotal: 7.65s\tremaining: 1.9s\n",
      "900:\tlearn: 1.7423695\ttotal: 8.61s\tremaining: 946ms\n",
      "999:\tlearn: 1.7334458\ttotal: 9.56s\tremaining: 0us\n",
      "save_dem\n",
      "demvfill_byML\n",
      "True\n",
      "read_dem\n",
      "mask_invalid_values\n",
      "interpolate_missing_values\n",
      "Learning rate set to 0.131835\n",
      "0:\tlearn: 140.9561634\ttotal: 26.3ms\tremaining: 26.2s\n",
      "100:\tlearn: 40.9401235\ttotal: 2.26s\tremaining: 20.1s\n",
      "200:\tlearn: 35.7386395\ttotal: 4.44s\tremaining: 17.6s\n",
      "300:\tlearn: 33.0267577\ttotal: 6.62s\tremaining: 15.4s\n",
      "400:\tlearn: 31.2417491\ttotal: 8.79s\tremaining: 13.1s\n",
      "500:\tlearn: 29.9839337\ttotal: 11s\tremaining: 10.9s\n",
      "600:\tlearn: 29.0668656\ttotal: 13.2s\tremaining: 8.74s\n",
      "700:\tlearn: 28.3086746\ttotal: 15.4s\tremaining: 6.55s\n",
      "800:\tlearn: 27.6313286\ttotal: 17.5s\tremaining: 4.36s\n",
      "900:\tlearn: 27.0961031\ttotal: 19.7s\tremaining: 2.17s\n",
      "999:\tlearn: 26.5971158\ttotal: 21.9s\tremaining: 0us\n",
      "save_dem\n",
      "demvfill_byML\n",
      "True\n",
      "read_dem\n",
      "mask_invalid_values\n",
      "interpolate_missing_values\n",
      "Learning rate set to 0.137681\n",
      "0:\tlearn: 7.5441400\ttotal: 34.5ms\tremaining: 34.5s\n",
      "100:\tlearn: 3.5811003\ttotal: 3.01s\tremaining: 26.8s\n",
      "200:\tlearn: 3.4106472\ttotal: 5.95s\tremaining: 23.7s\n",
      "300:\tlearn: 3.3656107\ttotal: 8.93s\tremaining: 20.7s\n",
      "400:\tlearn: 3.3501552\ttotal: 11.9s\tremaining: 17.8s\n",
      "500:\tlearn: 3.3413264\ttotal: 14.9s\tremaining: 14.8s\n"
     ]
    }
   ],
   "source": [
    "for tilename in tilenames:\n",
    "    #tilename = 'N10E105'\n",
    "    dem_ipath = f\"{tiles_xdpath}/{tilename}/{tilename}_tdem_DEM__Fw.tif\"\n",
    "    tile_odpath = f\"{outdir}/{tilename}/\" \n",
    "    os.makedirs(tile_odpath, exist_ok=True)\n",
    "    dem_opath = f\"{tile_odpath}/{tilename}_tdem_DEM__iML.tif\"\n",
    "\n",
    "    print(os.path.isfile(dem_ipath))\n",
    "    demvfill_byML(dem_ipath, dem_opath, model_type='catboost')\n",
    "    #print(dem_ipath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "models:\n",
    "- RF [x]: too expensive \n",
    "- CB [x]\n",
    "- same method as agglomerative :: not really got gpu - about 2mins tile at 30m -> should be 10 mins at 12 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agluon",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
